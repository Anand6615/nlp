{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement time (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for time\n"
     ]
    }
   ],
   "source": [
    "!pip install time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia-api\n",
      "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in d:\\myenv\\lib\\site-packages (from wikipedia-api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\myenv\\lib\\site-packages (from requests->wikipedia-api) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\myenv\\lib\\site-packages (from requests->wikipedia-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\myenv\\lib\\site-packages (from requests->wikipedia-api) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\myenv\\lib\\site-packages (from requests->wikipedia-api) (2024.8.30)\n",
      "Building wheels for collected packages: wikipedia-api\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15438 sha256=705efa2bd8af957e4c344115a37fdf2684b3248fa885f0a0e9ab2f483339e718\n",
      "  Stored in directory: c:\\users\\anand\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\33\\3c\\79\\b36253689d838af4a0539782853ac3cc38a83a6591ad570dde\n",
      "Successfully built wikipedia-api\n",
      "Installing collected packages: wikipedia-api\n",
      "Successfully installed wikipedia-api-0.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Wiki(page_title):\n",
    "    wiki = wikipediaapi.Wikipedia(user_agent=\"MyNLPProject/1.0\", language=\"en\")\n",
    "    page = wiki.page(page_title)\n",
    "\n",
    "    return page.summary if page.exists() else \" \"\n",
    "\n",
    "text = get_Wiki(\"Rolls-Royce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rolls-Royce (always hyphenated) may refer to:\\n\\nRolls-Royce Limited, a British manufacturer of cars and later aero engines, founded in 1906, now defunct'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rolls-Royce',\n",
       " '(',\n",
       " 'always',\n",
       " 'hyphenated',\n",
       " ')',\n",
       " 'may',\n",
       " 'refer',\n",
       " 'to',\n",
       " ':',\n",
       " 'Rolls-Royce',\n",
       " 'Limited',\n",
       " ',',\n",
       " 'a',\n",
       " 'British',\n",
       " 'manufacturer',\n",
       " 'of',\n",
       " 'cars',\n",
       " 'and',\n",
       " 'later',\n",
       " 'aero',\n",
       " 'engines',\n",
       " ',',\n",
       " 'founded',\n",
       " 'in',\n",
       " '1906',\n",
       " ',',\n",
       " 'now',\n",
       " 'defunct']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Porter Stemmer is one of the oldest and most commonly used stemming algorithms. It follows a set of heuristic rules to remove suffixes, making words easier to process. It consists of five steps of word reductions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_stem = time.time()\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "end_stem = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.0/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.4/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 2.9/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 3.9/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/12.8 MB 3.1 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.8 MB 3.2 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 3.2 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 3.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.5/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spacy.load(\"en_core_web_sm\"):\n",
    "Loads the small English language model (en_core_web_sm).\n",
    "The model contains:\n",
    "Tokenization\n",
    "POS tagging\n",
    "Dependency parsing\n",
    "Named Entity Recognition (NER)\n",
    "Lemmatization\n",
    "Why use en_core_web_sm?\n",
    "Lightweight (fast and efficient).\n",
    "Sufficient for basic NLP tasks.\n",
    "Works well for general lemmatization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lem = time.time()  \n",
    "doc = nlp(\" \".join(tokens))\n",
    "lemmatized_words = [token.lemma_ for token in doc]\n",
    "end_lem = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text Sample: ['Rolls-Royce', '(', 'always', 'hyphenated', ')', 'may', 'refer', 'to', ':', 'Rolls-Royce']\n",
      "Stemmed Words: ['rolls-royc', '(', 'alway', 'hyphen', ')', 'may', 'refer', 'to', ':', 'rolls-royc']\n",
      "Lemmatized Words: ['Rolls', '-', 'Royce', '(', 'always', 'hyphenate', ')', 'may', 'refer', 'to']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text Sample:\", tokens[:10])\n",
    "print(\"Stemmed Words:\", stemmed_words[:10])\n",
    "print(\"Lemmatized Words:\", lemmatized_words[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Analysis:\n",
      "Stemming Execution Time: 0.00100 seconds\n",
      "Lemmatization Execution Time: 0.02600 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPerformance Analysis:\")\n",
    "print(f\"Stemming Execution Time: {end_stem - start_stem:.5f} seconds\")\n",
    "print(f\"Lemmatization Execution Time: {end_lem - start_lem:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OTHER STEMMING MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lancaster Stemmer is more aggressive than the Porter Stemmer. It applies harder rules, which often lead to shorter stems that might not always be readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rolls-Royce (always hyphenated) may refer to:\\n\\nRolls-Royce Limited, a British manufacturer of cars and later aero engines, founded in 1906, now defunct'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['Rolls-Royce', '(', 'always', 'hyphenated', ')', 'may', 'refer', 'to', ':', 'Rolls-Royce', 'Limited', ',', 'a', 'British', 'manufacturer', 'of', 'cars', 'and', 'later', 'aero', 'engines', ',', 'founded', 'in', '1906', ',', 'now', 'defunct']\n",
      "Lancaster Stemmed: ['rolls-royce', '(', 'alway', 'hyph', ')', 'may', 'ref', 'to', ':', 'rolls-royce', 'limit', ',', 'a', 'brit', 'manufact', 'of', 'car', 'and', 'lat', 'aero', 'engin', ',', 'found', 'in', '1906', ',', 'now', 'defunct']\n"
     ]
    }
   ],
   "source": [
    "lancaster_stemmed = [lancaster.stem(word) for word in tokens]\n",
    "\n",
    "print(\"Original:\", tokens)\n",
    "print(\"Lancaster Stemmed:\", lancaster_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Snowball Stemmer, also known as Porter2, is an improved version of the Porter Stemmer. It is more refined, supports multiple languages, and is less aggressive than Lancaster.\n",
    "\n",
    "Accuracy: ~85%\n",
    "\n",
    "More refined and accurate than Porter.\n",
    "Supports multiple languages.\n",
    "Balances performance and accuracy well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "snowball_stemmed = [snowball.stem(word) for word in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['Rolls-Royce', '(', 'always', 'hyphenated', ')', 'may', 'refer', 'to', ':', 'Rolls-Royce', 'Limited', ',', 'a', 'British', 'manufacturer', 'of', 'cars', 'and', 'later', 'aero', 'engines', ',', 'founded', 'in', '1906', ',', 'now', 'defunct']\n",
      "Snowball Stemmed: ['rolls-royc', '(', 'alway', 'hyphen', ')', 'may', 'refer', 'to', ':', 'rolls-royc', 'limit', ',', 'a', 'british', 'manufactur', 'of', 'car', 'and', 'later', 'aero', 'engin', ',', 'found', 'in', '1906', ',', 'now', 'defunct']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\", tokens)\n",
    "print(\"Snowball Stemmed:\", snowball_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEMMATIZATION MODUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses WordNet, a lexical database of English words.\n",
    "Converts words to their dictionary form (lemma) based on POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "wordnet_lemmatized = [wordnet_lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['Rolls-Royce', '(', 'always', 'hyphenated', ')', 'may', 'refer', 'to', ':', 'Rolls-Royce', 'Limited', ',', 'a', 'British', 'manufacturer', 'of', 'cars', 'and', 'later', 'aero', 'engines', ',', 'founded', 'in', '1906', ',', 'now', 'defunct']\n",
      "WordNet Lemmatized: ['Rolls-Royce', '(', 'always', 'hyphenated', ')', 'may', 'refer', 'to', ':', 'Rolls-Royce', 'Limited', ',', 'a', 'British', 'manufacturer', 'of', 'car', 'and', 'later', 'aero', 'engine', ',', 'founded', 'in', '1906', ',', 'now', 'defunct']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\", tokens)\n",
    "print(\"WordNet Lemmatized:\", wordnet_lemmatized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
